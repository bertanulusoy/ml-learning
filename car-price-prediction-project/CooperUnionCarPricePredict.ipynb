{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset includes used vehicles' specifications such as model, year, engine as well as their prices. We will estimate the prices of used cars with using these features. It will be Supervised Learning as the price feature is given. In addition, since our estimation is price value which is real-valued, we will have solved the Regression problem.\n",
    "\n",
    "\n",
    "In our case first we will create a simple linear regression model. After that we will improve our model with using different algorithms.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Dataset\n",
    "First step is downloading the dataset. \n",
    "\n",
    "The dataset can be fetched with Kaggle CLI by using below command.\n",
    "\n",
    "#### kaggle datasets download -d CooperUnion/cardataset\n",
    "\n",
    "or you can also download the dataset from the Kaggle site with the link below:\n",
    "\n",
    "https://www.kaggle.com/CooperUnion/cardataset\n",
    "\n",
    "After downloading the dataset, we need to unzip the file to read the dataset.\n",
    "\n",
    "Let's read the dataset:\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Data\n",
    "\n",
    "To read and analyze the dataset we need to import some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read csv files, common action is to use `read_csv` function of the pandas library. The `read_csv` function returns `pandas.core.frame.DataFrame` object. After reading csv file as `DataFrame` object, we need to assign it to a variable which is in this case the `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With built-in `len` function of the Python, we find how many rows(records) there are?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11914"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first five rows of our DataFrame with `head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Year</th>\n",
       "      <th>Engine Fuel Type</th>\n",
       "      <th>Engine HP</th>\n",
       "      <th>Engine Cylinders</th>\n",
       "      <th>Transmission Type</th>\n",
       "      <th>Driven_Wheels</th>\n",
       "      <th>Number of Doors</th>\n",
       "      <th>Market Category</th>\n",
       "      <th>Vehicle Size</th>\n",
       "      <th>Vehicle Style</th>\n",
       "      <th>highway MPG</th>\n",
       "      <th>city mpg</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>MSRP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series M</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium unleaded (required)</td>\n",
       "      <td>335.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>rear wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Factory Tuner,Luxury,High-Performance</td>\n",
       "      <td>Compact</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>3916</td>\n",
       "      <td>46135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium unleaded (required)</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>rear wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Luxury,Performance</td>\n",
       "      <td>Compact</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>3916</td>\n",
       "      <td>40650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium unleaded (required)</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>rear wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Luxury,High-Performance</td>\n",
       "      <td>Compact</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>3916</td>\n",
       "      <td>36350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium unleaded (required)</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>rear wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Luxury,Performance</td>\n",
       "      <td>Compact</td>\n",
       "      <td>Coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>3916</td>\n",
       "      <td>29450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>1 Series</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium unleaded (required)</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>rear wheel drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Luxury</td>\n",
       "      <td>Compact</td>\n",
       "      <td>Convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>3916</td>\n",
       "      <td>34500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Make       Model  Year             Engine Fuel Type  Engine HP  \\\n",
       "0  BMW  1 Series M  2011  premium unleaded (required)      335.0   \n",
       "1  BMW    1 Series  2011  premium unleaded (required)      300.0   \n",
       "2  BMW    1 Series  2011  premium unleaded (required)      300.0   \n",
       "3  BMW    1 Series  2011  premium unleaded (required)      230.0   \n",
       "4  BMW    1 Series  2011  premium unleaded (required)      230.0   \n",
       "\n",
       "   Engine Cylinders Transmission Type     Driven_Wheels  Number of Doors  \\\n",
       "0               6.0            MANUAL  rear wheel drive              2.0   \n",
       "1               6.0            MANUAL  rear wheel drive              2.0   \n",
       "2               6.0            MANUAL  rear wheel drive              2.0   \n",
       "3               6.0            MANUAL  rear wheel drive              2.0   \n",
       "4               6.0            MANUAL  rear wheel drive              2.0   \n",
       "\n",
       "                         Market Category Vehicle Size Vehicle Style  \\\n",
       "0  Factory Tuner,Luxury,High-Performance      Compact         Coupe   \n",
       "1                     Luxury,Performance      Compact   Convertible   \n",
       "2                Luxury,High-Performance      Compact         Coupe   \n",
       "3                     Luxury,Performance      Compact         Coupe   \n",
       "4                                 Luxury      Compact   Convertible   \n",
       "\n",
       "   highway MPG  city mpg  Popularity   MSRP  \n",
       "0           26        19        3916  46135  \n",
       "1           28        19        3916  40650  \n",
       "2           28        20        3916  36350  \n",
       "3           28        18        3916  29450  \n",
       "4           28        18        3916  34500  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data\n",
    "\n",
    "At first glance at the dataset, it is noticed that the column names and their contents are not in the correct format, especially contents that may be categorical variables such as the `Driven_Wheels` column's content. \n",
    "\n",
    "First, we will normalize the column names by replacing all spaces with underscores and all letters with lowercase letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the manipulation, there is now more convenient format for the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['make', 'model', 'year', 'engine_fuel_type', 'engine_hp',\n",
       "       'engine_cylinders', 'transmission_type', 'driven_wheels',\n",
       "       'number_of_doors', 'market_category', 'vehicle_size', 'vehicle_style',\n",
       "       'highway_mpg', 'city_mpg', 'popularity', 'msrp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: *The columns wich are `object type` are assumed as `categorical data`. Beyond changing the form of categorical data, to increase our model's accuracy,  the categorical data needs to be preprocessed to be input to our model . We will work on this later.*\n",
    "\n",
    "\n",
    "<p> Also, to uniform the content of the columns which are object type, we implement the same form changes to them: \n",
    "\n",
    "Our rule is, again, ___replace all spaces with underscore and lowercase all letters.___\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do that:\n",
    "\n",
    "* select only columns with string values which are `object types`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_columns = list(df.dtypes[df.dtypes == 'object'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* make the appropriate changes to the content of the string columns according to the above rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in string_columns:\n",
    "    df[col] = df[col].str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the first five rows again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>engine_fuel_type</th>\n",
       "      <th>engine_hp</th>\n",
       "      <th>engine_cylinders</th>\n",
       "      <th>transmission_type</th>\n",
       "      <th>driven_wheels</th>\n",
       "      <th>number_of_doors</th>\n",
       "      <th>market_category</th>\n",
       "      <th>vehicle_size</th>\n",
       "      <th>vehicle_style</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>popularity</th>\n",
       "      <th>msrp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bmw</td>\n",
       "      <td>1_series_m</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium_unleaded_(required)</td>\n",
       "      <td>335.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>rear_wheel_drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>factory_tuner,luxury,high-performance</td>\n",
       "      <td>compact</td>\n",
       "      <td>coupe</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>3916</td>\n",
       "      <td>46135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bmw</td>\n",
       "      <td>1_series</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium_unleaded_(required)</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>rear_wheel_drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>luxury,performance</td>\n",
       "      <td>compact</td>\n",
       "      <td>convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>3916</td>\n",
       "      <td>40650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bmw</td>\n",
       "      <td>1_series</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium_unleaded_(required)</td>\n",
       "      <td>300.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>rear_wheel_drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>luxury,high-performance</td>\n",
       "      <td>compact</td>\n",
       "      <td>coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>3916</td>\n",
       "      <td>36350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bmw</td>\n",
       "      <td>1_series</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium_unleaded_(required)</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>rear_wheel_drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>luxury,performance</td>\n",
       "      <td>compact</td>\n",
       "      <td>coupe</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>3916</td>\n",
       "      <td>29450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bmw</td>\n",
       "      <td>1_series</td>\n",
       "      <td>2011</td>\n",
       "      <td>premium_unleaded_(required)</td>\n",
       "      <td>230.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>rear_wheel_drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>luxury</td>\n",
       "      <td>compact</td>\n",
       "      <td>convertible</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>3916</td>\n",
       "      <td>34500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  make       model  year             engine_fuel_type  engine_hp  \\\n",
       "0  bmw  1_series_m  2011  premium_unleaded_(required)      335.0   \n",
       "1  bmw    1_series  2011  premium_unleaded_(required)      300.0   \n",
       "2  bmw    1_series  2011  premium_unleaded_(required)      300.0   \n",
       "3  bmw    1_series  2011  premium_unleaded_(required)      230.0   \n",
       "4  bmw    1_series  2011  premium_unleaded_(required)      230.0   \n",
       "\n",
       "   engine_cylinders transmission_type     driven_wheels  number_of_doors  \\\n",
       "0               6.0            manual  rear_wheel_drive              2.0   \n",
       "1               6.0            manual  rear_wheel_drive              2.0   \n",
       "2               6.0            manual  rear_wheel_drive              2.0   \n",
       "3               6.0            manual  rear_wheel_drive              2.0   \n",
       "4               6.0            manual  rear_wheel_drive              2.0   \n",
       "\n",
       "                         market_category vehicle_size vehicle_style  \\\n",
       "0  factory_tuner,luxury,high-performance      compact         coupe   \n",
       "1                     luxury,performance      compact   convertible   \n",
       "2                luxury,high-performance      compact         coupe   \n",
       "3                     luxury,performance      compact         coupe   \n",
       "4                                 luxury      compact   convertible   \n",
       "\n",
       "   highway_mpg  city_mpg  popularity   msrp  \n",
       "0           26        19        3916  46135  \n",
       "1           28        19        3916  40650  \n",
       "2           28        20        3916  36350  \n",
       "3           28        18        3916  29450  \n",
       "4           28        18        3916  34500  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these chanes, you will see that we will preprocess the categorical variables easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='msrp', ylabel='Count'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The MSRP(Manufacture's suggested Retail Price) colums is our target variable, y, which is the value that we want to predict.\n",
    "# First steps of explotary data analysis should always be to look at what the values of y look like. \n",
    "# We typically do this by checking the distribution of y: a visual description of what the possible values of y can be and \n",
    "# how often they occur. This type of visualization is called a histogram.\n",
    "sns.histplot(df.msrp, bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='msrp', ylabel='Count'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We immediately notice that the distribution of prices has a very long tail. There are many cars with low prices on the \n",
    "# left side, but the number quickly drops, and there's a long tail of very few cars with high prices.\n",
    "# We can have a closer look by zooming in a bit and looking at values below $100,00\n",
    "sns.histplot(df.msrp[df.msrp < 100000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also notice a lot of cars that cost $1,000.\n",
    "The long tail makes it quite difficult for us to see the distribution, but it has an even\n",
    "stronger effect on a model: such distribution can greatly confuse the model, so it\n",
    "won’t learn well enough. One way to solve this problem is **log transformation**. If we\n",
    "apply the log function to the prices, it removes the undesired effect.\n",
    "\n",
    "The +1 part is important in cases that have zeros. The logarithm of zero is minus infinity,\n",
    "but the logarithm of one is zero. If our values are all non-negative, by adding 1, we\n",
    "make sure that the transformed values do not go below zero.\n",
    "For our specific case, zero values are not an issue — all the prices we have start at\n",
    "$1,000 — but it’s still a convention that we follow. NumPy has a function that performs\n",
    "this transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_price = np.log1p(df.msrp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='msrp', ylabel='Count'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(log_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, this transformation removes the long tail, and now the distribution resembles a bell-shaped curve. This distribution is not normal, of course, because of the\n",
    "large peak in lower prices, but the model can deal with it more easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a convenient function that checks for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make                    0\n",
       "model                   0\n",
       "year                    0\n",
       "engine_fuel_type        3\n",
       "engine_hp              69\n",
       "engine_cylinders       30\n",
       "transmission_type       0\n",
       "driven_wheels           0\n",
       "number_of_doors         6\n",
       "market_category      3742\n",
       "vehicle_size            0\n",
       "vehicle_style           0\n",
       "highway_mpg             0\n",
       "city_mpg                0\n",
       "popularity              0\n",
       "msrp                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we see is that MSRP — our target variable — doesn’t have any missing\n",
    "values. This result is good, because otherwise, such records won’t be useful to us: we\n",
    "always need to know the target value of an observation to use it for training the model.\n",
    "\n",
    "We need to deal with missing values later when we train the model, so we should\n",
    "keep this problem in mind. For now, we don’t do anything else with these features and\n",
    "proceed to the next step: setting up the validation framework so that we can train and\n",
    "test machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we learned previously, it’s important to set up the validation framework as early as\n",
    "possible to make sure that the models we train are good and can generalize — that\n",
    "is, that the model can be applied to new, unseen data. To do that, we put aside some\n",
    "data and train the model only on one part. Then we use the held-out dataset — the\n",
    "one we didn’t use for training — to make sure that the predictions of the model\n",
    "make sense.\n",
    "\n",
    "This step is important because we train the model by using \n",
    "optimization methods that fit the function g(X) to the data X. Sometimes these optimization methods pick up spurious patterns — patterns that appear to be real patterns to the model but in reality are random fluctuations. If we have a small training dataset in which all BMW cars cost only $10,000, for example, the model will think that this is true for all BMW cars in the world.\n",
    "[\n",
    "Bu adım önemlidir çünkü modeli kullanarak eğitiyoruz.\n",
    "g(X) fonksiyonunu veri X'e uyduran optimizasyon yöntemleri. Bazen bu optimizasyon yöntemleri, modele gerçek kalıplar gibi görünen ancak gerçekte rastgele dalgalanmalar olan sahte kalıplar alır.\n",
    "Örneğin, tüm BMW otomobillerinin yalnızca 10.000 dolara mal olduğu küçük bir eğitim veri setimiz varsa, model bunun dünyadaki tüm BMW otomobilleri için geçerli olduğunu düşünecektir.\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that this doesn’t happen, we use validation. Because the validation dataset\n",
    "is not used for training the model, the optimization method did not see this data.\n",
    "\n",
    "When we apply the model to this data, it emulates the case of applying the model to new data that we’ve never seen. If the validation dataset has BMW cars with prices higher than `$10,000`, but our model will predict `$10,000`on them, we will notice that the model doesn’t perform well on these examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we already know, we need to split the dataset into three parts: train, validation, and test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s split the DataFrame such that\n",
    "* 20% of data goes to validation.\n",
    "* 20% goes to test.\n",
    "* The remaining 60% goes to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into validation, test, and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11914"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets the number of rows in the DataFrame\n",
    "n = len(df)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7150"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculates how many rows should go to train, validation, and test\n",
    "n_val = int(0.2 * n)\n",
    "n_test = int(0.2 * n)\n",
    "n_train = n - (n_val + n_test)\n",
    "n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixes the random seed to make sure that the results are reproducible\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2735, 6720, 5878, ..., 6637, 2575, 7336])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a NumPy array with indices from 0 to (n–1), and shuffles it\n",
    "idx = np.arange(n)\n",
    "np.random.shuffle(idx)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>engine_fuel_type</th>\n",
       "      <th>engine_hp</th>\n",
       "      <th>engine_cylinders</th>\n",
       "      <th>transmission_type</th>\n",
       "      <th>driven_wheels</th>\n",
       "      <th>number_of_doors</th>\n",
       "      <th>market_category</th>\n",
       "      <th>vehicle_size</th>\n",
       "      <th>vehicle_style</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>city_mpg</th>\n",
       "      <th>popularity</th>\n",
       "      <th>msrp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>chevrolet</td>\n",
       "      <td>cobalt</td>\n",
       "      <td>2008</td>\n",
       "      <td>regular_unleaded</td>\n",
       "      <td>148.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>front_wheel_drive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>compact</td>\n",
       "      <td>coupe</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>1385</td>\n",
       "      <td>14410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6720</th>\n",
       "      <td>toyota</td>\n",
       "      <td>matrix</td>\n",
       "      <td>2012</td>\n",
       "      <td>regular_unleaded</td>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>front_wheel_drive</td>\n",
       "      <td>4.0</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>compact</td>\n",
       "      <td>4dr_hatchback</td>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "      <td>2031</td>\n",
       "      <td>19685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5878</th>\n",
       "      <td>subaru</td>\n",
       "      <td>impreza</td>\n",
       "      <td>2016</td>\n",
       "      <td>regular_unleaded</td>\n",
       "      <td>148.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>all_wheel_drive</td>\n",
       "      <td>4.0</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>compact</td>\n",
       "      <td>4dr_hatchback</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>640</td>\n",
       "      <td>19795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11190</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>vanagon</td>\n",
       "      <td>1991</td>\n",
       "      <td>regular_unleaded</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>rear_wheel_drive</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large</td>\n",
       "      <td>passenger_minivan</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>873</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4554</th>\n",
       "      <td>ford</td>\n",
       "      <td>f-150</td>\n",
       "      <td>2017</td>\n",
       "      <td>flex-fuel_(unleaded/e85)</td>\n",
       "      <td>385.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>four_wheel_drive</td>\n",
       "      <td>4.0</td>\n",
       "      <td>flex_fuel</td>\n",
       "      <td>large</td>\n",
       "      <td>crew_cab_pickup</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>5657</td>\n",
       "      <td>56260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>chevrolet</td>\n",
       "      <td>chevy_van</td>\n",
       "      <td>1998</td>\n",
       "      <td>regular_unleaded</td>\n",
       "      <td>200.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>rear_wheel_drive</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>midsize</td>\n",
       "      <td>cargo_van</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>1385</td>\n",
       "      <td>2052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11798</th>\n",
       "      <td>subaru</td>\n",
       "      <td>xv_crosstrek</td>\n",
       "      <td>2014</td>\n",
       "      <td>regular_unleaded</td>\n",
       "      <td>160.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>all_wheel_drive</td>\n",
       "      <td>4.0</td>\n",
       "      <td>crossover,hybrid</td>\n",
       "      <td>compact</td>\n",
       "      <td>4dr_suv</td>\n",
       "      <td>33</td>\n",
       "      <td>29</td>\n",
       "      <td>640</td>\n",
       "      <td>25995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6637</th>\n",
       "      <td>dodge</td>\n",
       "      <td>magnum</td>\n",
       "      <td>2006</td>\n",
       "      <td>regular_unleaded</td>\n",
       "      <td>250.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>all_wheel_drive</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>large</td>\n",
       "      <td>wagon</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>1851</td>\n",
       "      <td>29100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>honda</td>\n",
       "      <td>civic</td>\n",
       "      <td>2016</td>\n",
       "      <td>regular_unleaded</td>\n",
       "      <td>174.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>front_wheel_drive</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>midsize</td>\n",
       "      <td>sedan</td>\n",
       "      <td>42</td>\n",
       "      <td>31</td>\n",
       "      <td>2202</td>\n",
       "      <td>22200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7336</th>\n",
       "      <td>subaru</td>\n",
       "      <td>outback</td>\n",
       "      <td>2015</td>\n",
       "      <td>regular_unleaded</td>\n",
       "      <td>256.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>automatic</td>\n",
       "      <td>all_wheel_drive</td>\n",
       "      <td>4.0</td>\n",
       "      <td>crossover</td>\n",
       "      <td>midsize</td>\n",
       "      <td>4dr_suv</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>640</td>\n",
       "      <td>32995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11914 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             make         model  year          engine_fuel_type  engine_hp  \\\n",
       "2735    chevrolet        cobalt  2008          regular_unleaded      148.0   \n",
       "6720       toyota        matrix  2012          regular_unleaded      132.0   \n",
       "5878       subaru       impreza  2016          regular_unleaded      148.0   \n",
       "11190  volkswagen       vanagon  1991          regular_unleaded       90.0   \n",
       "4554         ford         f-150  2017  flex-fuel_(unleaded/e85)      385.0   \n",
       "...           ...           ...   ...                       ...        ...   \n",
       "2514    chevrolet     chevy_van  1998          regular_unleaded      200.0   \n",
       "11798      subaru  xv_crosstrek  2014          regular_unleaded      160.0   \n",
       "6637        dodge        magnum  2006          regular_unleaded      250.0   \n",
       "2575        honda         civic  2016          regular_unleaded      174.0   \n",
       "7336       subaru       outback  2015          regular_unleaded      256.0   \n",
       "\n",
       "       engine_cylinders transmission_type      driven_wheels  number_of_doors  \\\n",
       "2735                4.0            manual  front_wheel_drive              2.0   \n",
       "6720                4.0         automatic  front_wheel_drive              4.0   \n",
       "5878                4.0         automatic    all_wheel_drive              4.0   \n",
       "11190               4.0            manual   rear_wheel_drive              3.0   \n",
       "4554                8.0         automatic   four_wheel_drive              4.0   \n",
       "...                 ...               ...                ...              ...   \n",
       "2514                6.0         automatic   rear_wheel_drive              3.0   \n",
       "11798               4.0         automatic    all_wheel_drive              4.0   \n",
       "6637                6.0         automatic    all_wheel_drive              4.0   \n",
       "2575                4.0         automatic  front_wheel_drive              4.0   \n",
       "7336                6.0         automatic    all_wheel_drive              4.0   \n",
       "\n",
       "        market_category vehicle_size      vehicle_style  highway_mpg  \\\n",
       "2735                NaN      compact              coupe           33   \n",
       "6720          hatchback      compact      4dr_hatchback           32   \n",
       "5878          hatchback      compact      4dr_hatchback           37   \n",
       "11190               NaN        large  passenger_minivan           18   \n",
       "4554          flex_fuel        large    crew_cab_pickup           21   \n",
       "...                 ...          ...                ...          ...   \n",
       "2514                NaN      midsize          cargo_van           18   \n",
       "11798  crossover,hybrid      compact            4dr_suv           33   \n",
       "6637                NaN        large              wagon           22   \n",
       "2575                NaN      midsize              sedan           42   \n",
       "7336          crossover      midsize            4dr_suv           27   \n",
       "\n",
       "       city_mpg  popularity   msrp  \n",
       "2735         24        1385  14410  \n",
       "6720         25        2031  19685  \n",
       "5878         28         640  19795  \n",
       "11190        16         873   2000  \n",
       "4554         15        5657  56260  \n",
       "...         ...         ...    ...  \n",
       "2514         13        1385   2052  \n",
       "11798        29         640  25995  \n",
       "6637         15        1851  29100  \n",
       "2575         31        2202  22200  \n",
       "7336         20         640  32995  \n",
       "\n",
       "[11914 rows x 16 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uses the array with indices to get a shuffled DataFrame\n",
    "df_shuffled = df.iloc[idx]\n",
    "df_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the shuffled DataFrame into train(7150), validation(2382), and test(2382)\n",
    "df_train = df_shuffled.iloc[:n_train].copy()\n",
    "df_val = df_shuffled.iloc[n_train:n_train+n_val].copy()\n",
    "df_test = df_shuffled.iloc[n_train+n_val:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the DataFrame is split into three parts, and we can continue. Our initial analysis showed a long tail in the distribution of prices, and to remove its effect, we need to apply the log transformation. We can do that for each DataFrame separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.log1p(df_train.msrp.values)\n",
    "y_val = np.log1p(df_val.msrp.values)\n",
    "y_test = np.log1p(df_test.msrp.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.57574708,  9.887663  ,  9.89323518, ..., 10.45380308,\n",
       "       12.62248099, 10.54061978])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid accidentally using the target variable later, let’s remove it from the dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train['msrp']\n",
    "del df_val['msrp']\n",
    "del df_test['msrp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the validation split is done, we can go to the next step: training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing the initial data analysis, we are ready to train a model. The problem we are solving is a regression problem: the goal is to predict a number — the price of a car. For this project we will use the simplest regression model: linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "supervised machine learning model has the form\n",
    "\n",
    "$y\\approx g(X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, for this single observation, the previous formula looks like\n",
    "\n",
    "$y_{i}\\approx g(x_{i})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have n features, our vector $x_{i}$ is n-dimensional, so it has n components:\n",
    "\n",
    "$x_{i}=(x_{i1}, x_{i2},...,x_{in})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it has n components, we can write the function **g** as a function with n parameters, which is the same as the previous formula:\n",
    "\n",
    "$x_{i}=g(x_{i})=g(x_{i1}, x_{i2},...,x_{in})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s pick a few numerical features and ignore the rest for now. We can start with\n",
    "horsepower, MPG in the city, and popularity:\n",
    "\n",
    "**engine_hp**      453\n",
    "\n",
    "**city_mpg**       11\n",
    "\n",
    "**popularity**     86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let’s assign these features to $x_{i1}, x_{i2}, and x_{i3}$, respectively. This way, we get the feature\n",
    "vector xi with three components:\n",
    "$x_{i}=(x_{i1},x_{i2},x_{i3})=(453,11,86)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make it easier to understand, we can translate this mathematical notation to Python.\n",
    "def g(xi):\n",
    "    # xi is a list with n elements\n",
    "    # do something with xi\n",
    "    # return the result\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, the variable $x_{i}$ is our vector $x_{i}$. Depending on implementation, $x_{i}$ could\n",
    "be a list with n elements or a NumPy array of size n.\n",
    "For the car described previously, $x_{i}$ is a list with three elements:\n",
    "\n",
    "$x_{i}=[453, 11, 86]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we apply the function g to a vector $x_{i}$, it produces **y_pred** as the output, which\n",
    "is the g’s prediction for $x_{i}$:\n",
    "\n",
    "y_pred = $g(x_{i})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If **g** is the linear regression model, it has the following form:\n",
    "\n",
    "$g(x_{i})=g(x_{i1},x_{i2},...,x_{in}) = w_{0} + x_{i1} w_{1} + x_{i2} w_{2} + ... + x_{in} w_{n} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables $w_{0}, w_{1}, w_{2},$ …, wn  are the parameters of the model:\n",
    "\n",
    "* $w_{0}$ is the _bias_ term.\n",
    "* $w_{1}, w_{2},...,w_{n}$ are the _weights_ for each feature $x_{i1},x_{i2},...,x_{in}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the formula shorter, let’s use sum notation:\n",
    "\n",
    "$g(x_{i}) = g(x_{i1},x_{i2},...,x_{in}) = w_{0} + \\sum \\limits _{j=1} ^{n} X_{ij} w_{j} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These weights are what the model learns when we train it. To better understand how\n",
    "the model uses these weights, let’s consider the following values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w_{0}$    -> 7.17    \n",
    "\n",
    "$w_{1}$     -> 0.01        \n",
    "\n",
    "$w_{2}$     -> 0.04 \n",
    "\n",
    "$w_{3}$    -> 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we want to translate this model to Python, it will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = 7.17\n",
    "# [w1 w2 w3 ]\n",
    "w = [0.01, 0.04, 0.002]\n",
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_algebra(xi):\n",
    "    result = w0\n",
    "    for j in range(n):\n",
    "        result = result + xi[j] * w[j]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put all the feature weights inside a single list w — just like we did with xi previously.\n",
    "All we need to do now is loop over these weights and multiply them by the corresponding\n",
    "feature values.\n",
    "\n",
    "Our example has three features, so n = 3, and we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$g(x_{i}) = g(x_{i1},x_{i2},x_{i3}) = w_{0} + \\sum \\limits _{j=1} ^{3} X_{ij} w_{j} = w_{0} + x_{i1} w_{1} + x_{i2} w_{2} + x_{i3} w_{3} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is exactly what we have in the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = w0 + xi[0] * w[0] + xi[1] * w[1] + xi[2] * w[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s see what happens when we apply the model to our observation xi and\n",
    "replace the weights with their values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$g(x_{i}) = 7.17 + 453 * 0.01 + 11 * 0.04 + 86 * 0.002 = 12.31$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction we get for this observation is 12.31. Remember that during preprocessing,\n",
    "we applied the logarithmic transformation to our target variable y. This is why the\n",
    "model we trained on this data also predicts the logarithm of the price. To undo the transformation,\n",
    "we need to take the exponent of the logarithm. In our case, when we do\n",
    "it, the prediction becomes $603,000:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exp(12.31 + 1) = 603,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bias term (7.17) is the value we would predict if we didn’t know anything about\n",
    "the car; it serves as a baseline.\n",
    "\n",
    "We do know something about the car, however: horsepower, MPG in the city, and\n",
    "popularity. These features are the xi1, xi2, and xi3 features, each of which tells us something\n",
    "about the car. We use this information to adjust the baseline.\n",
    "\n",
    "Let’s consider the first feature: horsepower. The weight for this feature is 0.01,\n",
    "which means that for each extra unit of horsepower, we adjust the baseline by adding\n",
    "0.01. Because we have 453 horses in the engine, we add 4.53 to the baseline: 453\n",
    "horses · 0.01 = 4.53.\n",
    "\n",
    "The same happens with MPG. Each additional mile per gallon increases the price\n",
    "by 0.04, so we add 0.44: 11 MPG · 0.04 = 0.44.\n",
    "\n",
    "Finally, we take popularity into account. In our example, each mention in the Twitter\n",
    "stream results in a 0.002 increase. In total, popularity contributes 0.172 to the final\n",
    "prediction.\n",
    "\n",
    "This is exactly why we get 12.31 when we combine everything\n",
    "\n",
    "$g(x_{i}) = 7.17 + 453 * 0.01 + 11 * 0.04 + 86 * 0.002 = 12.31$\n",
    "\n",
    "       Bias   Horsepower  MPG     Popularity\n",
    "       \n",
    "              4.53        0.44    0.172"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we now think of both features and weights as vectors $x_{i}$ and $w$, respectively, we\n",
    "can replace the sum of the elements of these vectors with a dot product between\n",
    "them:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_{i} ^{T} w = \\sum \\limits _{j=1} ^{n} x_{ij} w_{j} = x_{i1} w_{1} + x_{i2} w_{2} + x_{i3} w_{3} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product is a way of multiplying two vectors: we multiply corresponding elements\n",
    "of the vectors and then sum the results.\n",
    "\n",
    "The translation of the formula for dot product to the code is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(xi, w):\n",
    "    n = len(w)\n",
    "    result = 0.0\n",
    "    for j in range(n):\n",
    "        result = result + xi[j] * w[j]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the new notation, we can rewrite the entire equation for linear regression as\n",
    "\n",
    "$g(x_{i})=w_{0} + x_{i} ^{T} w$\n",
    "\n",
    "where\n",
    "\n",
    "* $w_{0}$ is the bias term.\n",
    "* $w$ is the n-dimensional vector of weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the new dot function, so the linear regression function in Python\n",
    "becomes very short:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(xi):\n",
    "    return w0 + dot(xi, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if $x_{i}$ and $w$ are NumPy arrays, we can use the built-in dot method for\n",
    "multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(xi):\n",
    "    return w0 + xi.dot(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it even shorter, we can combine $w_{0}$ and $w$ into one (n+1)-dimensional vector\n",
    "by prepending $w_{0}$ to $w$ right in front of $w_{1}$:\n",
    "\n",
    "$w=(w_{0},w_{1},w_{2},...,w_{n})$\n",
    "\n",
    "In Python, this is very easy to do. If we already have the old weights in a list $w$, all we\n",
    "need to do is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = [w0] + w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the plus operator in Python concatenates lists, so [1] + [2, 3, 4] will\n",
    "create a new list with four elements: [1, 2, 3, 4]. In our case, $w$ is already a list, so we\n",
    "create a new $w$ with one extra element at the beginning: $w_{0}$.\n",
    "\n",
    "Because now $w$ becomes a (n+1)-dimensional vector, we also need to adjust the feature\n",
    "vector $x_{i}$ so that the dot product between them still works. We can do this easily by\n",
    "adding a dummy feature $x_{i0}$, which always takes the value 1. Then we prepend this\n",
    "new dummy feature to $x_{i}$ right before $x_{i1}$:\n",
    "\n",
    "$x_{i}=(x_{i0},x_{i1},x_{i2},...x_{in})=(1,x_{i1},x_{i2},...,x_{in})$\n",
    "\n",
    "Or, in code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = [1] + xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these modifications, we can express the model as the dot product between\n",
    "the new $x_{i}$ and the new $w$:\n",
    "\n",
    "$g(x_{i})=x_{i} ^{T} w$\n",
    "\n",
    "The translation to the code is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = 7.17\n",
    "w = [0.01, 0.04, 0.002]\n",
    "w = [w0] + w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regrssion(xi):\n",
    "    xi = [1] + xi\n",
    "    return dot(xi, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to consider the bigger picture again and talk about the matrix form.\n",
    "There are many observations and $x_{i}$ is one of them. Thus, we have m feature vectors $x_{1},\n",
    "x_{2}, …, x_{i}, …, x_{m},$ and each of these vectors consists of n+1 features:\n",
    "\n",
    "\n",
    "$x_{1}=(1, x_{11},x_{12},..,x_{1n})$\n",
    "\n",
    "$x_{2}=(1, x_{21},x_{22},..,x_{2n})$\n",
    "\n",
    "           ...\n",
    "\n",
    "$x_{i}=(1, x_{i1},x_{i2},..,x_{in})$\n",
    "\n",
    "           ...\n",
    "\n",
    "$x_{m}=(1, x_{m1},x_{m2},..,x_{mn})$\n",
    "\n",
    "We can put these vectors together as rows of a matrix.\n",
    "\n",
    "Let’s see how it looks in code. We can take a few rows from the training dataset, such\n",
    "as the first, second, and tenth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [1, 148, 24, 1385]\n",
    "x2 = [1, 132, 25, 2031]\n",
    "x10 = [1, 453, 11, 86]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s put the rows together in another list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x1 + x2 + x10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List X now contains three lists. We can think of it as a 3x4 matrix — a matrix with three\n",
    "rows and four columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[1, 148, 24, 1385],\n",
    "    [1, 132, 25, 2031],\n",
    "    [1, 453, 11, 86]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column of this matrix is a feature:\n",
    "\n",
    "* The first column is a dummy feature with “1.”\n",
    "\n",
    "* The second column is the engine horsepower.\n",
    "\n",
    "* The third — MPG in the city.\n",
    "\n",
    "* And the last one — popularity, or the number of mentions in a Twitter stream.\n",
    "\n",
    "We already learned that to make a prediction for a single feature vector, we need to\n",
    "calculate the dot product between this feature vector and the weights vector. Now we\n",
    "have a matrix $X$, which in Python is a list of feature vectors. To make predictions for all\n",
    "the rows of the matrix, we can simply iterate over all rows of $X$ and compute the dot\n",
    "product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for xi in X:\n",
    "    pred = dot(xi, w)\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linear algebra, this is the matrix-vector multiplication: we multiply the matrix $X$ by\n",
    "the vector $w$. The formula for linear regression becomes\n",
    "\n",
    "$g(X)=w_{0}+ Xw$\n",
    "\n",
    "The result is an array with predictions for each row of X.\n",
    "\n",
    "The translation to NumPy becomes straightforward:\n",
    "\n",
    "predictions=X.dot(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weight vector $w$ can be computed with the following formula:\n",
    "\n",
    "$w=(X^{T}X)^{-1}X{^T}y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's translate to NumPy:\n",
    "* $X{^T}$ is the transpose of $X$. In NumPy, it's $X.T$\n",
    "* $X{^T}X$ is a matrix-matrix multiplication, which we can do with the $dot$ method from NumPy: $X.T.dot(X)$\n",
    "* $X{^-1}$ is the inverse of $X$. We can $np.linalg.inv$ function to calculate the inverse.\n",
    "\n",
    "So the formula above translates directly to:\n",
    "\n",
    "$inv(X.T.dot(X)).dot(X.T).dot(y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the normal equation, we need to do the following:\n",
    "\n",
    "* Create a function that takes in a matrix $X$ with features and a vector $y$ with the target.\n",
    "* Add a dummy column(the feature that is always set to 1) to the matrix $X$.\n",
    "* Train the model: compute the weights $w$ by using the normal equation.\n",
    "* Split this $w$ into the _bias_ $w_{0}$ and the rest of the weights, and return them.\n",
    "\n",
    "The last step -- splitting $w$ into the _bias_ term and the rest -- is optional and mostly for convenience; otherwise, we need to add the dummy column every time we want to make predictions instead of doing it once during training.\n",
    "\n",
    "Let's implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regression(X, y):\n",
    "    ## adding the dummy column##\n",
    "    \n",
    "    # Creates an array that contains only ones\n",
    "    ones = np.ones(X.shape[0])\n",
    "    # Adds the array of 1's as the first column of X\n",
    "    X = np.column_stack([ones, X])\n",
    "    \n",
    "    ## normal equation formula##\n",
    "    \n",
    "    # Computes X.T.X\n",
    "    XTX = X.T.dot(X)\n",
    "    # Computes the inverse of X.T.X\n",
    "    XTX_inv = np.linalg.inv(XTX)\n",
    "    # Computes the rest of the normal equation\n",
    "    w = XTX_inv.dot(X.T).dot(y)\n",
    "    \n",
    "    # Splits the weights vector into the bias and the rest of the weights\n",
    "    return w[0], w[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If weights are split into the bias term and the rest, the linear regression formula for making predictions changes slightly:\n",
    "\n",
    "$g(X)=w_{0} + Xw$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is still very easy to translate to NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = w[0] + X.dot(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use it for our project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = np.array([1, 1])\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[2,3], [4,5]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 4, 5]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.column_stack([ones, X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $column__stack$ takes a list of NumPy arrays and stacks them in columns. In our case, the function appends the array with ones as the first column of the matrix.\n",
    "\n",
    "We now have a function for training a linear regression model at our disposal, so let's use it to build a simple baseline solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline solution\n",
    "\n",
    "To be able to use it, we need to have some data: a matrix $X$ and a vector with the target variable $y$. We have already prepared the $y$, but we still don't have the $X$: what we have right noe is a data frame, not a matrix. So we need to extract some features from our dataset to create this matrix X.\n",
    "\n",
    "In the previous example, we used only three features. This time, we include a couple more features and use the following columns:\n",
    "* engine_hp\n",
    "* engine_cylinders\n",
    "* highway_mpg\n",
    "* city_mpg\n",
    "* popularity\n",
    "\n",
    "Let's select the features from the data frame and write them to a new variable, df_num:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = ['engine_hp', 'engine_cylinders', 'highway_mpg', 'city_mpg', 'popularity']\n",
    "df_num = df_train[base]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has missing values,so we need to do something because the linear regression model cannot deal with missing values automatically.\n",
    "\n",
    "The simplest possible approach is to fill the missing values with zeros. We can use the $fillna$ method from Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df_num.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method may not be the best way to deal with missing values, but often, it's good enough. If we set the missing feature value to zero, the respective feature is simply ignored.\n",
    "\n",
    "**NOTE:** An alternative option is to replace the missing values with the average values. For some variables, for example, the number of cylinders, the value of zero doesn't make much sense: a car cannot have zero cylinders. However, this will make our code more complex and won't have a significant impact on the results. That's why we follow a simpler approach and replace missing values with zeros.\n",
    "\n",
    "In our case, we have five features, so the formula is:\n",
    "\n",
    "$g(X_{i})=w_{0} + x_{i1}w_{1} + x_{i2}w_{2} + x_{i3}w_{3} + x_{i4}w_{4} + x_{i5}w_{5}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to convert this DataFrame to a NumPy array. The easiest way to do is to use its $values$ property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_num.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train is a matrix -- a two-dimensional NumPy array. We can use a input to our linear_regression function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_0, w = train_linear_regression(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just trained the first model! Now we can apply it to the training data to see how well it predicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = w_0 + X_train.dot(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how good the predictions are, we can use $histplot$ -- a function from $Seaborn$ for plotting histograms that we used previously -- to plot the predicted values and compare them with the actual prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f958c17c610>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y_pred, label='prediction')\n",
    "sns.histplot(y_train, label='target')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the plot that the distribution of values we predicted looks quite different from the actual values. This result may indicate that the model is not powerful enough to capture the distribution of the target variable. This shouldn't be a suprise to us: the model we used is quite basic and includes only five very simple features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE: Evaluating model quality\n",
    "\n",
    "Looking at plots and comparing the distributions of the actual target variable with the predictions is a good way to evaluate quality, but we cannot do this every time we change something in the model. Instead, we need to use a metric that quantifies the quality of the model. We can use many metrics to evaluate how well a regression model behaves.\n",
    "The most commonly used one is __root mean squared error__ --- RMSE for short.\n",
    "\n",
    "RMSE tells us how large the errors are that our model makes. Its computed with the following formula:\n",
    "\n",
    "$RMSE = \\sqrt{\\frac{1}{m} \\sum \\limits _{i=1} ^{m}(g(x_{i})-y_{i})^{2}}$\n",
    "\n",
    "Let's try to understand the equition:\n",
    "\n",
    "$(g(x_{i})-y_{i})^{2}$\n",
    "\n",
    "This is the difference between the prediction we make for the observation and actual target value for that observation. Then we use square of the difference, which gives a lot more weight to larger differences.\n",
    "\n",
    "For example:\n",
    "* If we predict 9.5, and actual value is 9.6, the difference is 0.1, so its aquare is 0.01, which is quite small. But if we predict 7.3, and the actual value is 10.3, the difference is 3, and the square of the difference is 9. This is SE part of RMSE.\n",
    "\n",
    "Next we have sum: $\\sum \\limits _{i=1} ^{m}$\n",
    "This summation goes over all $m$ observations and puts all the squared errors together into a single number.\n",
    "\n",
    "If we divide this sum by $m$, we get the mean squared error: $\\frac{1}{m}$\n",
    "\n",
    "Finally, we take the square root of that:\n",
    "\n",
    "$RMSE = \\sqrt{\\frac{1}{m} \\sum \\limits _{i=1} ^{m}(g(x_{i})-y_{i})^{2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{Y} = g(x_{i}) \\hat{\\beta}_{0} + \\sum \\limits _{j=1} ^{3} X_{ij} w_{j} = w_{0} + x_{i1} w_{1} + x_{i2} w_{2} + x_{i3} w_{3} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
